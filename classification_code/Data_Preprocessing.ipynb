{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HeavyWater Classification Test\n",
    " This program contains Three main parts:\n",
    " 1. Data preprocessing\n",
    " 2. Classifiers training\n",
    " 3. Results comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, sys, os, csv, time\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel,f_classif,SelectKBest\n",
    "# feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "## test ensemble methods\n",
    "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,ExtraTreesClassifier,VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "1. Read and add metadata, Delete null and duplicated rows\n",
    "2. Check if the classes are balanced by counting the number of document for each category\n",
    "3. Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Shape:                   (62204, 2)\n",
      "Dataset (without null rows) Shape:        (62204, 2)\n",
      "Dataset (without duplicated rows) Shape:  (60548, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60548 entries, 0 to 62203\n",
      "Data columns (total 2 columns):\n",
      "Labels    60548 non-null object\n",
      "Values    60542 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "## Step 1\n",
    "# read data from csv file\n",
    "dataset = pd.read_csv('data/shuffled-full-set-hashed.csv',header=None,sep=',')\n",
    "dataset.columns=['Labels','Values']\n",
    "print \"Original Dataset Shape:                  \", dataset.shape\n",
    "# drop rows that contain null values and duplicated\n",
    "dataset=pd.DataFrame(dataset)\n",
    "dataset=dataset[pd.notnull(dataset)]\n",
    "print \"Dataset (without null rows) Shape:       \", dataset.shape\n",
    "dataset=dataset.drop_duplicates()\n",
    "print \"Dataset (without duplicated rows) Shape: \", dataset.shape\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Labels  Values\n",
      "0                      BILL   18449\n",
      "1             POLICY CHANGE   10229\n",
      "2       CANCELLATION NOTICE    9571\n",
      "3                    BINDER    8590\n",
      "4      DELETION OF INTEREST    4779\n",
      "5      REINSTATEMENT NOTICE    4295\n",
      "6               DECLARATION     966\n",
      "7        CHANGE ENDORSEMENT     866\n",
      "8            RETURNED CHECK     730\n",
      "9         EXPIRATION NOTICE     719\n",
      "10       NON-RENEWAL NOTICE     618\n",
      "11              BILL BINDER     277\n",
      "12  INTENT TO CANCEL NOTICE     227\n",
      "13              APPLICATION     226\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAIBCAYAAAA2z6clAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8880b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Step 2\n",
    "# Check if the classes are balanced by counting the number of document for each category\n",
    "sorted_counts=dataset.groupby('Labels').Values.count().sort_values(ascending=False)\n",
    "summary=pd.DataFrame(sorted_counts).reset_index()\n",
    "print summary\n",
    "fig=plt.figure(figsize=(8,6))\n",
    "sorted_counts.plot.bar(ylim=0)\n",
    "plt.title('# of documents per category')\n",
    "plt.ylabel('# of Occurrences')\n",
    "plt.xlabel('Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Summary\n",
    "There are 62204 samples in the dataset, and each sample have two component: Document label and Word Values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "Check the number of document for each category (document labels) to see if the classes are balanced or imbalanced.\n",
    "From the figure, we can see that there are 14 categories, and \"BILL\",\"Policy change\", \"Binder\", and \"cancellation Notice\" have more samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label enCoding:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "Label Decoding:  ['APPLICATION' 'BILL' 'BILL BINDER' 'BINDER' 'CANCELLATION NOTICE'\n",
      " 'CHANGE ENDORSEMENT' 'DECLARATION' 'DELETION OF INTEREST'\n",
      " 'EXPIRATION NOTICE' 'INTENT TO CANCEL NOTICE' 'NON-RENEWAL NOTICE'\n",
      " 'POLICY CHANGE' 'REINSTATEMENT NOTICE' 'RETURNED CHECK']\n"
     ]
    }
   ],
   "source": [
    "## Step 3 Label Encoding\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(dataset['Labels'])\n",
    "pickle.dump(encoder, open('labelEncoder.pkl','wb')) # save model using Pickle\n",
    "dataset['ID']=encoder.transform(dataset['Labels'])\n",
    "print \"Label enCoding: \", range(14)\n",
    "print \"Label Decoding: \", encoder.inverse_transform(range(14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Goals: Small Size (file size), Computational time (Traning especially testing), and accuracy\n",
    "\n",
    "### Addressing overfitting:\n",
    "\n",
    "1. reduce the number of features (manually or select from model)\n",
    "\n",
    "2. Regularization (keep all the features, decrease the maganitude/values of parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features (min_df=3,ngram_range=(1, 2)): 814258\n",
      "Extracted features (min_df=10,ngram_range=(1, 2)): 229546\n",
      "Extracted features (min_df=10,ngram_range=(1, 3)): 336138\n",
      "Extracted features (min_df=10,ngram_range=(1, 5)): 446320\n",
      "Extracted features (min_df=20,ngram_range=(1, 3)): 157843\n",
      "Extracted features (min_df=5,max_df=0.95,ngram_range=(1, 3)): 739988\n"
     ]
    }
   ],
   "source": [
    "# get X : words; Y: Labels/Classes\n",
    "#Y=dataset['ID']\n",
    "#X=[str(i) for i in dataset['Values']]\n",
    "# create training (90%) and test sets (10%)\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "## feature extraction on training set\n",
    "#tfidf = TfidfVectorizer(sublinear_tf=True, min_df=3, norm='l2', encoding='utf-8', ngram_range=(1, 2)) # 2 Grams\n",
    "#features = tfidf.fit_transform(X_train, Y_train)\n",
    "print 'Extracted features (min_df=3,ngram_range=(1, 2)):',features.shape[1]\n",
    "#tfidf_10 = TfidfVectorizer(sublinear_tf=True, min_df=10, norm='l2', encoding='utf-8', ngram_range=(1, 2)) # 2 Grams\n",
    "#features_10 = tfidf_10.fit_transform(X_train, Y_train)\n",
    "print 'Extracted features (min_df=10,ngram_range=(1, 2)):',features_10.shape[1]\n",
    "#tfidf_N3 = TfidfVectorizer(sublinear_tf=True, min_df=10, norm='l2', encoding='utf-8', ngram_range=(1, 3)) # 2 Grams\n",
    "#features_N3 = tfidf_N3.fit_transform(X_train, Y_train)\n",
    "print 'Extracted features (min_df=10,ngram_range=(1, 3)):',features_N3.shape[1]\n",
    "#tfidf_N5 = TfidfVectorizer(sublinear_tf=True, min_df=10, norm='l2', encoding='utf-8', ngram_range=(1, 5)) # 2 Grams\n",
    "#features_N5 = tfidf_N5.fit_transform(X_train, Y_train)\n",
    "print 'Extracted features (min_df=10,ngram_range=(1, 5)):',features_N5.shape[1]\n",
    "#tfidf_N3_20 = TfidfVectorizer(sublinear_tf=True, min_df=20, norm='l2', encoding='utf-8', ngram_range=(1, 3)) # 2 Grams\n",
    "#features_N3_20 = tfidf_N3_20.fit_transform(X_train, Y_train)\n",
    "print 'Extracted features (min_df=20,ngram_range=(1, 3)):',features_N3_20.shape[1]\n",
    "tfidf_N3_5_max = TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.95,norm='l2', encoding='utf-8', ngram_range=(1, 3)) # 2 Grams\n",
    "features_N3_5_max = tfidf_N3_5_max.fit_transform(X_train, Y_train)\n",
    "print 'Extracted features (min_df=5,max_df=0.95,ngram_range=(1, 3)):',features_N3_5_max.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Analysis\n",
    "\n",
    "The number of extracted features with min_df=3 and 2 Ngram is 814,258, and this number is too large for efficient classification analysis. \n",
    "\n",
    "The following steps can be used to reduce the number of features without affecting the accuracy.\n",
    "\n",
    "1. Use gridsearchCV to select the smallest K value for a classifier (such as Logistic regression which has good performance on text classification)\n",
    "\n",
    "2. select the best K features using different methods (manually and select from model), and then compare the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        st... penalty='l2', random_state=None,\n",
       "          solver='sag', tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__max_features': [100000, 400000, 800000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use gridsearchCV to select the smallest K value for Logistic Regression\n",
    "cvt=CountVectorizer(min_df=3,ngram_range=(1, 2))\n",
    "tft=TfidfTransformer(sublinear_tf=True)\n",
    "clf=LogisticRegression(solver='sag',class_weight='balanced',max_iter=100)\n",
    "pipe=Pipeline([('vect', cvt),('tfidf', tft),('clf',clf)])\n",
    "parameters={'vect__max_features':[100000,400000,800000]}\n",
    "grid_LR_large=GridSearchCV(pipe,cv=3,param_grid=parameters)\n",
    "grid_LR_large.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_vect__max_features</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212.030667</td>\n",
       "      <td>12.162333</td>\n",
       "      <td>0.752527</td>\n",
       "      <td>0.802884</td>\n",
       "      <td>100000</td>\n",
       "      <td>{u'vect__max_features': 100000}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.786694</td>\n",
       "      <td>0.840167</td>\n",
       "      <td>0.704752</td>\n",
       "      <td>0.753177</td>\n",
       "      <td>0.766131</td>\n",
       "      <td>0.815308</td>\n",
       "      <td>3.194034</td>\n",
       "      <td>0.386301</td>\n",
       "      <td>0.034810</td>\n",
       "      <td>0.036584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352.891333</td>\n",
       "      <td>13.085667</td>\n",
       "      <td>0.799135</td>\n",
       "      <td>0.861499</td>\n",
       "      <td>400000</td>\n",
       "      <td>{u'vect__max_features': 400000}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.810472</td>\n",
       "      <td>0.873269</td>\n",
       "      <td>0.801467</td>\n",
       "      <td>0.867806</td>\n",
       "      <td>0.785459</td>\n",
       "      <td>0.843423</td>\n",
       "      <td>4.028733</td>\n",
       "      <td>0.062404</td>\n",
       "      <td>0.010344</td>\n",
       "      <td>0.012975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>467.646667</td>\n",
       "      <td>14.542333</td>\n",
       "      <td>0.800638</td>\n",
       "      <td>0.864577</td>\n",
       "      <td>800000</td>\n",
       "      <td>{u'vect__max_features': 800000}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801159</td>\n",
       "      <td>0.865117</td>\n",
       "      <td>0.773175</td>\n",
       "      <td>0.837954</td>\n",
       "      <td>0.827584</td>\n",
       "      <td>0.890661</td>\n",
       "      <td>3.236461</td>\n",
       "      <td>0.663470</td>\n",
       "      <td>0.022214</td>\n",
       "      <td>0.021521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0     212.030667        12.162333         0.752527          0.802884   \n",
       "1     352.891333        13.085667         0.799135          0.861499   \n",
       "2     467.646667        14.542333         0.800638          0.864577   \n",
       "\n",
       "  param_vect__max_features                           params  rank_test_score  \\\n",
       "0                   100000  {u'vect__max_features': 100000}                3   \n",
       "1                   400000  {u'vect__max_features': 400000}                2   \n",
       "2                   800000  {u'vect__max_features': 800000}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.786694            0.840167           0.704752   \n",
       "1           0.810472            0.873269           0.801467   \n",
       "2           0.801159            0.865117           0.773175   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            0.753177           0.766131            0.815308      3.194034   \n",
       "1            0.867806           0.785459            0.843423      4.028733   \n",
       "2            0.837954           0.827584            0.890661      3.236461   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.386301        0.034810         0.036584  \n",
       "1        0.062404        0.010344         0.012975  \n",
       "2        0.663470        0.022214         0.021521  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_large=grid_LR_large.cv_results_\n",
    "pd.DataFrame(results_large).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        st... penalty='l2', random_state=None,\n",
       "          solver='sag', tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__max_features': [3000, 5000, 10000, 30000, 60000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use gridsearchCV to select the smallest K value for Logistic Regression\n",
    "cvt=CountVectorizer(min_df=3,ngram_range=(1, 2))\n",
    "tft=TfidfTransformer(sublinear_tf=True)\n",
    "clf=LogisticRegression(solver='sag',class_weight='balanced',max_iter=100)\n",
    "pipe=Pipeline([('vect', cvt),('tfidf', tft),('clf',clf)])\n",
    "parameters={'vect__max_features':[3000,5000,10000,30000,60000]}\n",
    "grid_LR=GridSearchCV(pipe,cv=10,param_grid=parameters)\n",
    "grid_LR.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_vect__max_features</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150.7997</td>\n",
       "      <td>3.3095</td>\n",
       "      <td>0.657891</td>\n",
       "      <td>0.673297</td>\n",
       "      <td>3000</td>\n",
       "      <td>{u'vect__max_features': 3000}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.711504</td>\n",
       "      <td>0.725816</td>\n",
       "      <td>0.601519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699719</td>\n",
       "      <td>0.707580</td>\n",
       "      <td>0.598347</td>\n",
       "      <td>0.622390</td>\n",
       "      <td>0.626819</td>\n",
       "      <td>0.632367</td>\n",
       "      <td>2.649242</td>\n",
       "      <td>0.134632</td>\n",
       "      <td>0.064393</td>\n",
       "      <td>0.064448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164.8713</td>\n",
       "      <td>3.3973</td>\n",
       "      <td>0.704548</td>\n",
       "      <td>0.725786</td>\n",
       "      <td>5000</td>\n",
       "      <td>{u'vect__max_features': 5000}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.742697</td>\n",
       "      <td>0.767201</td>\n",
       "      <td>0.746946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612957</td>\n",
       "      <td>0.638219</td>\n",
       "      <td>0.749256</td>\n",
       "      <td>0.772304</td>\n",
       "      <td>0.732970</td>\n",
       "      <td>0.752239</td>\n",
       "      <td>4.100098</td>\n",
       "      <td>0.176731</td>\n",
       "      <td>0.045176</td>\n",
       "      <td>0.044663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>187.6856</td>\n",
       "      <td>3.4157</td>\n",
       "      <td>0.714309</td>\n",
       "      <td>0.736656</td>\n",
       "      <td>10000</td>\n",
       "      <td>{u'vect__max_features': 10000}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600264</td>\n",
       "      <td>0.612234</td>\n",
       "      <td>0.723671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735250</td>\n",
       "      <td>0.753693</td>\n",
       "      <td>0.777355</td>\n",
       "      <td>0.812177</td>\n",
       "      <td>0.689980</td>\n",
       "      <td>0.710495</td>\n",
       "      <td>10.693381</td>\n",
       "      <td>0.177493</td>\n",
       "      <td>0.046356</td>\n",
       "      <td>0.051367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>229.3037</td>\n",
       "      <td>3.4214</td>\n",
       "      <td>0.755483</td>\n",
       "      <td>0.788047</td>\n",
       "      <td>30000</td>\n",
       "      <td>{u'vect__max_features': 30000}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.779997</td>\n",
       "      <td>0.822753</td>\n",
       "      <td>0.787554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778218</td>\n",
       "      <td>0.808907</td>\n",
       "      <td>0.714380</td>\n",
       "      <td>0.744376</td>\n",
       "      <td>0.787698</td>\n",
       "      <td>0.818312</td>\n",
       "      <td>6.922355</td>\n",
       "      <td>0.069675</td>\n",
       "      <td>0.031607</td>\n",
       "      <td>0.034749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256.1694</td>\n",
       "      <td>3.4587</td>\n",
       "      <td>0.779580</td>\n",
       "      <td>0.820787</td>\n",
       "      <td>60000</td>\n",
       "      <td>{u'vect__max_features': 60000}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.807394</td>\n",
       "      <td>0.853585</td>\n",
       "      <td>0.775834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763014</td>\n",
       "      <td>0.800796</td>\n",
       "      <td>0.726281</td>\n",
       "      <td>0.775937</td>\n",
       "      <td>0.804067</td>\n",
       "      <td>0.841174</td>\n",
       "      <td>5.301719</td>\n",
       "      <td>0.096844</td>\n",
       "      <td>0.023436</td>\n",
       "      <td>0.022716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       150.7997           3.3095         0.657891          0.673297   \n",
       "1       164.8713           3.3973         0.704548          0.725786   \n",
       "2       187.6856           3.4157         0.714309          0.736656   \n",
       "3       229.3037           3.4214         0.755483          0.788047   \n",
       "4       256.1694           3.4587         0.779580          0.820787   \n",
       "\n",
       "  param_vect__max_features                          params  rank_test_score  \\\n",
       "0                     3000   {u'vect__max_features': 3000}                5   \n",
       "1                     5000   {u'vect__max_features': 5000}                4   \n",
       "2                    10000  {u'vect__max_features': 10000}                3   \n",
       "3                    30000  {u'vect__max_features': 30000}                2   \n",
       "4                    60000  {u'vect__max_features': 60000}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score       ...         \\\n",
       "0           0.711504            0.725816           0.601519       ...          \n",
       "1           0.742697            0.767201           0.746946       ...          \n",
       "2           0.600264            0.612234           0.723671       ...          \n",
       "3           0.779997            0.822753           0.787554       ...          \n",
       "4           0.807394            0.853585           0.775834       ...          \n",
       "\n",
       "   split7_test_score  split7_train_score  split8_test_score  \\\n",
       "0           0.699719            0.707580           0.598347   \n",
       "1           0.612957            0.638219           0.749256   \n",
       "2           0.735250            0.753693           0.777355   \n",
       "3           0.778218            0.808907           0.714380   \n",
       "4           0.763014            0.800796           0.726281   \n",
       "\n",
       "   split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
       "0            0.622390           0.626819            0.632367      2.649242   \n",
       "1            0.772304           0.732970            0.752239      4.100098   \n",
       "2            0.812177           0.689980            0.710495     10.693381   \n",
       "3            0.744376           0.787698            0.818312      6.922355   \n",
       "4            0.775937           0.804067            0.841174      5.301719   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.134632        0.064393         0.064448  \n",
       "1        0.176731        0.045176         0.044663  \n",
       "2        0.177493        0.046356         0.051367  \n",
       "3        0.069675        0.031607         0.034749  \n",
       "4        0.096844        0.023436         0.022716  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=grid_LR.cv_results_\n",
    "pd.DataFrame(results).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For extracted 814,258 features (min_df=3,ngram_range=(1, 2)),\n",
    "\n",
    "If K (the number of selected feature) is between 30000 to 60000, the accuracy is between 75% to 78% for logistic regression method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "        s... penalty='l2', random_state=None,\n",
       "          solver='sag', tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__max_features': [5000, 10000, 30000, 60000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use gridsearchCV to select the smallest K value for Logistic Regression\n",
    "cvt=CountVectorizer(min_df=10,ngram_range=(1, 3))\n",
    "tft=TfidfTransformer(sublinear_tf=True)\n",
    "clf=LogisticRegression(solver='sag',class_weight='balanced',max_iter=100)\n",
    "pipe=Pipeline([('vect', cvt),('tfidf', tft),('clf',clf)])\n",
    "parameters={'vect__max_features':[5000,10000,30000,60000]}\n",
    "grid_LR=GridSearchCV(pipe,cv=5,param_grid=parameters)\n",
    "grid_LR.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_vect__max_features</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>371.4022</td>\n",
       "      <td>13.8730</td>\n",
       "      <td>0.648130</td>\n",
       "      <td>0.667418</td>\n",
       "      <td>5000</td>\n",
       "      <td>{u'vect__max_features': 5000}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.720535</td>\n",
       "      <td>0.734556</td>\n",
       "      <td>0.604524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608110</td>\n",
       "      <td>0.631007</td>\n",
       "      <td>0.643099</td>\n",
       "      <td>0.662270</td>\n",
       "      <td>0.664354</td>\n",
       "      <td>0.686415</td>\n",
       "      <td>16.120513</td>\n",
       "      <td>0.638906</td>\n",
       "      <td>0.042513</td>\n",
       "      <td>0.040516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>414.9068</td>\n",
       "      <td>14.9528</td>\n",
       "      <td>0.729900</td>\n",
       "      <td>0.757333</td>\n",
       "      <td>10000</td>\n",
       "      <td>{u'vect__max_features': 10000}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.757841</td>\n",
       "      <td>0.785968</td>\n",
       "      <td>0.692949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718038</td>\n",
       "      <td>0.745458</td>\n",
       "      <td>0.746923</td>\n",
       "      <td>0.769121</td>\n",
       "      <td>0.733746</td>\n",
       "      <td>0.759243</td>\n",
       "      <td>9.473063</td>\n",
       "      <td>1.425052</td>\n",
       "      <td>0.022768</td>\n",
       "      <td>0.020155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>468.3142</td>\n",
       "      <td>15.1156</td>\n",
       "      <td>0.760719</td>\n",
       "      <td>0.799008</td>\n",
       "      <td>30000</td>\n",
       "      <td>{u'vect__max_features': 30000}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.793249</td>\n",
       "      <td>0.831062</td>\n",
       "      <td>0.755862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730096</td>\n",
       "      <td>0.772399</td>\n",
       "      <td>0.772280</td>\n",
       "      <td>0.814042</td>\n",
       "      <td>0.752086</td>\n",
       "      <td>0.787668</td>\n",
       "      <td>8.539532</td>\n",
       "      <td>1.176141</td>\n",
       "      <td>0.021110</td>\n",
       "      <td>0.020850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524.3746</td>\n",
       "      <td>15.4118</td>\n",
       "      <td>0.780422</td>\n",
       "      <td>0.824454</td>\n",
       "      <td>60000</td>\n",
       "      <td>{u'vect__max_features': 60000}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.804969</td>\n",
       "      <td>0.849149</td>\n",
       "      <td>0.759247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755368</td>\n",
       "      <td>0.798761</td>\n",
       "      <td>0.801933</td>\n",
       "      <td>0.845482</td>\n",
       "      <td>0.780587</td>\n",
       "      <td>0.827199</td>\n",
       "      <td>7.621785</td>\n",
       "      <td>0.953934</td>\n",
       "      <td>0.020696</td>\n",
       "      <td>0.021159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       371.4022          13.8730         0.648130          0.667418   \n",
       "1       414.9068          14.9528         0.729900          0.757333   \n",
       "2       468.3142          15.1156         0.760719          0.799008   \n",
       "3       524.3746          15.4118         0.780422          0.824454   \n",
       "\n",
       "  param_vect__max_features                          params  rank_test_score  \\\n",
       "0                     5000   {u'vect__max_features': 5000}                4   \n",
       "1                    10000  {u'vect__max_features': 10000}                3   \n",
       "2                    30000  {u'vect__max_features': 30000}                2   \n",
       "3                    60000  {u'vect__max_features': 60000}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score       ...         \\\n",
       "0           0.720535            0.734556           0.604524       ...          \n",
       "1           0.757841            0.785968           0.692949       ...          \n",
       "2           0.793249            0.831062           0.755862       ...          \n",
       "3           0.804969            0.849149           0.759247       ...          \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.608110            0.631007           0.643099   \n",
       "1           0.718038            0.745458           0.746923   \n",
       "2           0.730096            0.772399           0.772280   \n",
       "3           0.755368            0.798761           0.801933   \n",
       "\n",
       "   split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "0            0.662270           0.664354            0.686415     16.120513   \n",
       "1            0.769121           0.733746            0.759243      9.473063   \n",
       "2            0.814042           0.752086            0.787668      8.539532   \n",
       "3            0.845482           0.780587            0.827199      7.621785   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.638906        0.042513         0.040516  \n",
       "1        1.425052        0.022768         0.020155  \n",
       "2        1.176141        0.021110         0.020850  \n",
       "3        0.953934        0.020696         0.021159  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=grid_LR.cv_results_\n",
    "pd.DataFrame(results).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score based on original features (814,258):       0.849545829893\n",
      "F1 score based on selected K top term frequency features (k=30000):   0.864905037159\n",
      "F1 score based on selected K features (SelectKBest(f_classif)):  0.844095788604\n",
      "F1 score based on selected K features (SelectFromModel):    0.853014037985\n"
     ]
    }
   ],
   "source": [
    "# train and test model on logistic regression\n",
    "clf=LogisticRegression()\n",
    "pipe_0=Pipeline([('tfidf', TfidfVectorizer(sublinear_tf=True, min_df=3, norm='l2', encoding='utf-8', ngram_range=(1, 3))),('clf',clf)])\n",
    "pipe_0.fit(X_train, Y_train)\n",
    "Y_pred_0=pipe_0.predict(X_test)\n",
    "print \"F1 score based on original features (814,258):      \",f1_score(Y_test,Y_pred_0,average='micro')\n",
    "## features selection\n",
    "# based on 1. self define; 2. selectKBest(chi2); 3. select from model\n",
    "k=30000\n",
    "cvt=CountVectorizer(min_df=3,ngram_range=(1, 2),max_features=k)\n",
    "tft=TfidfTransformer(sublinear_tf=True)\n",
    "clf=LogisticRegression()\n",
    "pipe_1=Pipeline([('vect', cvt),('tfidf', tft),('clf',clf)])\n",
    "pipe_1.fit(X_train, Y_train)\n",
    "Y_pred_1=pipe_1.predict(X_test)\n",
    "print \"F1 score based on selected K top term frequency features (k=30000):  \",f1_score(Y_test,Y_pred_1,average='micro')\n",
    "clf=LogisticRegression()\n",
    "pipe_2=Pipeline([('tfidf', TfidfVectorizer(sublinear_tf=True, min_df=3, norm='l2', encoding='utf-8', ngram_range=(1, 2))),('selection',SelectKBest(f_classif,k=k)),('clf',clf)])\n",
    "pipe_2.fit(X_train, Y_train)\n",
    "Y_pred_2=pipe_2.predict(X_test)\n",
    "print \"F1 score based on selected K features (SelectKBest(f_classif)): \",f1_score(Y_test,Y_pred_2,average='micro')\n",
    "clf=LogisticRegression()\n",
    "pipe_3=Pipeline([('tfidf', TfidfVectorizer(sublinear_tf=True, min_df=3, norm='l2', encoding='utf-8', ngram_range=(1, 2))),('sfm',SelectFromModel(clf)),('clf',clf)])\n",
    "pipe_3.fit(X_train, Y_train)\n",
    "Y_pred_3=pipe_3.predict(X_test)\n",
    "print \"F1 score based on selected K features (SelectFromModel):   \",f1_score(Y_test,Y_pred_3,average='micro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
